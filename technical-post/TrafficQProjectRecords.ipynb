{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68a44ec6-965b-4976-a031-0e60de6cf792",
   "metadata": {},
   "source": [
    "# All Roads Lead to Kdb: the technical counterpart\n",
    "\n",
    "This post is a follow-up to our previous article, [All Roads Lead to Kdb](https://www.habla.dev/blog/2023/07/31/all-roads-lead-to-pykx.html), in which we introduced the utility of the PyKX library from the perspective of Emma Monad, the CTO of a large and fictional company known as Mad Flow. Complementing this C-level perspective, this post is aimed at Pythonist programmers who are eager to delve into the technical details that were left unexplained in the aforementioned article. Eloy, Jes√∫s, and F√©lix will be the fictional characters assisting us in this endeavor to understand both the goals of the traffic improvement use case undertaken by Mad Flow, as well as the technical nuances of the role played by PyKX within it. In general, and similarly to the results shown in this [post](https://kx.com/blog/accelerating-python-workflows-using-pykx/) on the [KX developer blog](https://kx.com/resources/developer-blog/) by Morrison and Crone, which we highly recommend reading, we'll observe a significant speed advantage of the resulting PyKX code over the initial Pandas implementation.\n",
    "\n",
    "The post will be structured as follows:\n",
    "\n",
    "* [**The Use Case**](#t2): First, we will explain the traffic improvement use case itself, including its goals, data sources, and expected results. In this section, you will find references to the necessary data sources required to execute all the code in this notebook.\n",
    "* [**PyKX migration**](#t3): Next, we will demonstrate how to offload the heavy processing to kdb+/q using PyKX, while remaining within the Python environment! This PyKX-powered Pythonic version will likely be the fastest way to start taking advantage of the kdb+/q environment.\n",
    "* [**pykx.q migration**](#t4): Lastly, we will elaborate on the process of transitioning the code to pure kdb+/q, while utilizing PyKX to continue relying on the Pythonic code you wish to retain. This PyKX-powered kdb+/q version is presented for those interested in adopting kdb+/q more extensively. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbfdce8-55cd-4f50-b0c9-cf58af1ff73e",
   "metadata": {},
   "source": [
    "## The Use Case<a class=\"anchor\" id=\"t2\"></a>\n",
    "\n",
    "With the goal of predicting traffic congestion in the presence of rain, Mad Flow invested a significant amount of time in preparing and ingesting weather and traffic data into an LSTM model. This effort was in line with other [studies](https://www.mdpi.com/1424-8220/20/13/3749) that aimed to forecast traffic patterns using LSTM models based on air pollution. And similar to findings from studies conducted in cities such as [Manchester](https://pure.manchester.ac.uk/ws/portalfiles/portal/72721911/DEXA_Camera_8_pages.pdf), [Shenzhen](https://ieeexplore.ieee.org/document/8964560) and [Belgrade](https://www.safetylit.org/citations/index.php?fuseaction=citations.viewdetails&citationIds[]=citjournalarticle_716898_14), our results project a weekday traffic volume increase of 5-15% during peak hours when rain is present. \n",
    "\n",
    "As is usual in projects associated with smart cities, the data is notably heterogeneous, demanding substantial preparatory efforts. The next sections will describe the data sources, the cleaning and interpretation processes, as well as the model used.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b30330-2b08-4ac1-b26c-5fcf1a3ac898",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data sources <a class=\"anchor\" id=\"t21\"></a>\n",
    "\n",
    "The [Madrid City Council](https://datos.madrid.es/portal/site/egob) offers weather and traffic data, which includes both real-time and historical records. For the purpose of model training, only the historical data is necessary. These CSV-formatted datasets are organized by months spanning from the year 2018 to the present.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b> üîç You can access the different datasets required to run this notebook from the following links: \n",
    "        <ul>\n",
    "            <li> <a href=\"https://datos.madrid.es/egob/catalogo/300352-141-meteorologicos-horarios.csv\">Weather data</a>\n",
    "            <li> <a href=\"https://datos.madrid.es/egob/catalogo/300360-1-meteorologicos-estaciones.csv\">Weather stations</a>\n",
    "            <li> <a href=\"https://datos.madrid.es/egob/catalogo/208627-115-transporte-ptomedida-historico.zip\">Traffic data</a>\n",
    "            <li> <a href=\"https://datos.madrid.es/egob/catalogo/202468-170-intensidad-trafico.csv\">Traffic stations</a>\n",
    "        </ul>\n",
    "    </b>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "**Weather data**\n",
    "\n",
    "The following table presents a snapshot of the kind of information that we can find in the [weather dataset](https://datos.madrid.es/egob/catalogo/300352-141-meteorologicos-horarios.csv):\n",
    "\n",
    "|    |   weather_station |   magnitude |   year |   month |   day |    H01 | V01   | ...|\n",
    "|---:|------------------:|-----------:|-------:|--------:|------:|-------:|------:|:------|\n",
    "|  0 |               108 |         81 |   2022 |      12 |    22 |  270   | N     | ...|\n",
    "|  1 |               108 |         82 |   2022 |      12 |    22 |    9   | N     |...|\n",
    "|  2 |               108 |         83 |   2022 |      12 |    22 |   94.7 | N     |...|\n",
    "|  3 |               108 |         86 |   2022 |      12 |    22 | 1031   | N     |...|\n",
    "|  4 |               108 |         87 |   2022 |      12 |    22 |    2   | N     |...|\n",
    "\n",
    "Each row records several information about a particular meteorological station: \n",
    "\n",
    "* The 'magnitude', which indicates the type of meteorological data recorded in the respective row (e.g. 81 - wind, 82 - direction, ..., 89 - rainfall)\n",
    "* In columns 'H01' and 'V01', the value for the data type indicated by the 'magnitude' column, along with its validity status, respectively.\n",
    "* In columns 'year', 'month' and 'day', the time at which the measurement is recorded.\n",
    "\n",
    "In addition to this information, we will also need the geographical coordinates of the different stations, which can be found in a separate [table](https://datos.madrid.es/egob/catalogo/300360-1-meteorologicos-estaciones.csv) provided by the Madrid City Council.\n",
    "\n",
    "\n",
    "(TBD: show the station 108)\n",
    "|    |   weather_station |   Longitude |   Latitude |\n",
    "|---:|------------------:|------------:|-----------:|\n",
    "|  0 |                 4 |    -3.71226 |    40.4239 |\n",
    "|  1 |                 8 |    -3.68232 |    40.4216 |\n",
    "|  2 |                16 |    -3.63924 |    40.44   |\n",
    "|  3 |                18 |    -3.73184 |    40.3948 |\n",
    "|  4 |                24 |    -3.74734 |    40.4194 |\n",
    "\n",
    "**Traffic data**\n",
    "\n",
    "Traffic sensors are located at traffic lights across the city of Madrid. The collected data gathers various measurements of the road conditions, including speed and traffic volume. All of these metrics are encapsulated in the 'load' metric, represented as a percentage that quantifies congestion. The structure of the [traffic table](https://datos.madrid.es/egob/catalogo/208627-115-transporte-ptomedida-historico.zip) is as follows: \n",
    "\n",
    "|    |   traffic_station | tipo_elem   |   intensidad |   ocupacion |   load |   vmed | error   |   periodo_integracion | date                |\n",
    "|---:|------------------:|:------------|-------------:|------------:|-------:|-------:|:--------|----------------------:|:--------------------|\n",
    "|  0 |              1001 | M30         |         3240 |           9 |      0 |     59 | N       |                     5 | 2022-12-01 00:00:00 |\n",
    "|  1 |              1001 | M30         |         3240 |           9 |      0 |     59 | N       |                     5 | 2022-12-01 00:15:00 |\n",
    "|  2 |              1001 | M30         |          300 |           1 |      0 |     66 | N       |                     5 | 2022-12-01 00:30:00 |\n",
    "\n",
    "\n",
    "The table also contains a column for the date and another that identifies the sensor that will be used to link it with its coordinates using the next [traffic stations table](https://datos.madrid.es/egob/catalogo/202468-170-intensidad-trafico.csv):\n",
    "\n",
    "|    | \"tipo_elem\"   |   \"distrito\" |   \"id\" | \"cod_cent\"   | \"nombre\"                                                          |   \"utm_x\" |     \"utm_y\" |   Longitude |   Latitude |\n",
    "|---:|:--------------|-------------:|-------:|:-------------|:------------------------------------------------------------------|----------:|------------:|------------:|-----------:|\n",
    "|  0 | \"URB\"         |            4 |   3840 | \"01001\"      | \"Jose Ortega y Gasset E-O - P¬∫ Castellana-Serrano\"                |    441615 | 4.47577e+06 |    -3.68832 |    40.4305 |\n",
    "|  1 | \"URB\"         |            4 |   3841 | \"01002\"      | \"Jose Ortega y Gasset O-E - Serrano-P¬∫ Castellana\"                |    441706 | 4.47577e+06 |    -3.68726 |    40.4305 |\n",
    "|  2 | \"URB\"         |            1 |   3842 | \"01003\"      | \"P¬∫ Recoletos N-S - Almirante-Prim\"                               |    441319 | 4.47484e+06 |    -3.69173 |    40.4221 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53238242-3c2c-44bb-ac7a-0be7b99111de",
   "metadata": {},
   "source": [
    "### The Cleaning  <a class=\"anchor\" id=\"t22\"></a>\n",
    "\n",
    "After loading the data, the next step was to prepare it for analysis and modeling. Given the heterogeneous nature of the datasets, data cleaning will be performed separately, and the data will be consolidated into a single table at a later stage.\n",
    "\n",
    "#### Weather\n",
    "\n",
    "The steps followed to clean the climate table are:\n",
    "\n",
    "1. In the weather dataset we first have the date separated into day, month and year, but in traffic all these data are together. This is why the columns have been grouped into a date column of shape: ```day-month-year```. \n",
    "\n",
    "2. We also transform each hour value measurement and its validity into independent rows and take the opportunity to remove invalid measurements:\n",
    "\n",
    "|       | hour            |   value |\n",
    "|------:|:----------------|--------:|\n",
    "|     0 | 0 days 00:00:00 |    7.1  |\n",
    "|     1 | 0 days 00:00:00 |    6.8  |\n",
    "|     2 | 0 days 00:00:00 |    2.8  |\n",
    "|     3 | 0 days 00:00:00 |    5.6  |\n",
    "\n",
    "3. To homogenize the time measure with the traffic table we join the date with the time. The new date shape is ```date-month-year hour:minute:second```\n",
    "\n",
    "4. Finally, we convert the different types of measurement into columns so that it looks more organized:\n",
    "\n",
    "|      | date                |   weather_station |   direction |   humidity |   pressure |   rainfall |   solar |   temperature |   wind |\n",
    "|-----:|:--------------------|------------------:|------------:|-----------:|-----------:|-----------:|--------:|--------------:|-------:|\n",
    "|    0 | 2022-12-01 00:00:00 |                 4 |           0 |          0 |          0 |        0   |       0 |           7.1 |   0    |\n",
    "|    1 | 2022-12-01 00:00:00 |                 8 |           0 |         67 |          0 |        0   |       0 |           9.4 |   0    |\n",
    "|    2 | 2022-12-01 00:00:00 |                16 |           0 |         73 |          0 |        0   |       0 |           8.9 |   0    |\n",
    "\n",
    "#### Traffic\n",
    "\n",
    "Regarding the traffic table, the steps followed were the following:\n",
    "\n",
    "1. First we filter out the values with measurement errors. In the documentation they tell us that these values are represented with an \"N\". \n",
    "\n",
    "2. We only keep the load measurement, which is what we are interested in for the analysis.\n",
    "\n",
    "3. We group the values for each date and station and calculate the average.\n",
    "\n",
    "#### Location\n",
    "\n",
    "In order to combine the two previous tables, it's necessary to establish a correspondence between the traffic sensors and the weather stations. This can be achieved by employing a distance matrix and identifying the nearest pairs among the two types of station.  While direct measurement of this distance using coordinates is possible, we opted for the [Haversine distance](https://en.wikipedia.org/wiki/Haversine_formula) which calculates the distance in meters between a pair of coordinates, offering a clearer representation of distances.  This can be observed in the following heatmap, where the distances range from 0 to 20 km:\n",
    "\n",
    "<figure>\n",
    "<img src=\"image_source/heatmap3.png\">\n",
    "<figcaption style = \"text-align: center\"> <b>Figure 1:</b> Heatmap of distances in km between weather and traffic stations </figcaption>\n",
    "</figure>\n",
    "    \n",
    "#### The Final Table <a class=\"anchor\" id=\"t23\"></a>\n",
    "\n",
    "After preparing the three tables - weather, traffic, and distance - we merge them. Since the weather table has time intervals of 1 hour, whereas the traffic data is in 15-minute intervals, we will combine these tables using an 'asof' join. Ultimately, we can incorporate time and day-of-the-week information to analyze its relationship with traffic congestion.\n",
    "\n",
    "|    | date                |   traffic_station |   load |   Distance |   Closest |   weather_station |   direction |   humidity |   pressure |   rainfall |   solar |   temperature |   wind |   weekday |   hour |\n",
    "|---:|:--------------------|------------------:|-------:|-----------:|----------:|------------------:|------------:|-----------:|-----------:|-----------:|--------:|--------------:|-------:|----------:|-------:|\n",
    "|  0 | 2022-12-01 00:00:00 |              1001 |      0 |         15 |         1 |                 8 |           0 |         67 |          0 |          0 |       0 |           9.4 |      0 |         3 |      0 |\n",
    "|  1 | 2022-12-01 00:00:00 |              1002 |      0 |         15 |         1 |                 8 |           0 |         67 |          0 |          0 |       0 |           9.4 |      0 |         3 |      0 |\n",
    "|  2 | 2022-12-01 00:00:00 |              1003 |      0 |         14 |         1 |                 8 |           0 |         67 |          0 |          0 |       0 |           9.4 |      0 |         3 |      0 |\n",
    "|  3 | 2022-12-01 00:00:00 |              1006 |      0 |         15 |         1 |                 8 |           0 |         67 |          0 |          0 |       0 |           9.4 |      0 |         3 |      0 |\n",
    "|  4 | 2022-12-01 00:00:00 |              1009 |      0 |         14 |         0 |                 4 |           0 |          0 |          0 |          0 |       0 |           7.1 |      0 |         3 |      0 |\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457c9d92",
   "metadata": {},
   "source": [
    "### Data interpretation <a class=\"anchor\" id=\"t24\"></a>\n",
    "\n",
    "Traffic is highly time-dependent. The data will be filtered to extract the peak moments where traffic typically is heavier. This will enhance our understanding of the data. Weekdays tend to have more traffic than holidays, just as daytime have higher traffic flow than nighttime. In the following figure underscores the evident seasonality within the dataset:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "    <td style='text-align:center;'>\n",
    "<figure>\n",
    "<img src=\"image_source/loadperhour.png\">\n",
    "<figcaption style = \"text-align: center\">   <b>Figure 2:</b> Load per Hour </figcaption>\n",
    "</figure>\n",
    " </td>\n",
    "    <td>\n",
    "<figure>\n",
    "<img src=\"image_source/loadperweekday.png\">\n",
    "<figcaption style = \"text-align: center\">   <b>Figure 3:</b> Load per Weekday </figcaption>\n",
    "</figure>\n",
    "            </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Regarding the Rainfall-Load dependency we started seeing that rainy days are very few on our dataset:\n",
    "\n",
    "|       |       rainfall |\n",
    "|:------|---------------:|\n",
    "| count | 841068         |\n",
    "| mean  |      0.0130932 |\n",
    "| std   |      0.194232  |\n",
    "| min   |      0         |\n",
    "| 50%   |      0         |\n",
    "| 90%   |      0         |\n",
    "| 99.9% |      2.9       |\n",
    "| max   |     10.9       |\n",
    "\n",
    "Examining the percentiles of the precipitation column, it becomes evident that there are very few recordings with rain. To address this, measurements were categorized into distinct classes based on the intensity of rain. Consequently, a separate analysis was conducted for data involving heavy rain, moderate to light rain, and no rain. The analysis was done hourly to mitigate the temporal dependence of traffic. The average increase in traffic congestion hours due to rain ranges from 5% to 14%, consistent with the studies presented in [the Use Case](#t12) chapter.\n",
    "\n",
    "<figure>\n",
    "<img src=\"image_source/rainfall.png\">\n",
    "<figcaption style = \"text-align: center\"> <b>Figure 4:</b> The average traffic load per hour for the measurements with heavy rain (blue), moderate rain (brown) and no rain (green).</figcaption>\n",
    "</figure>\n",
    "\n",
    "To verify that these differences between groups are significant, we can perform an anova test. And we see that in all hours there is great evidence that the load is different between the different levels of rain. For example, for hour 12:\n",
    "\n",
    "|             |          sum_sq |    df |        F |       PR(>F) |\n",
    "|:------------|----------------:|------:|---------:|-------------:|\n",
    "| C(rainfall) | 37650.7         |     6 |  20.1144 |   1.3346e-23 |\n",
    "| Residual    |     8.01363e+06 | 25687 | nan      | nan          |\n",
    "\n",
    "It was decided to include rainfall within the model. The rest of the meteorological conditions did not give such a clear result, so they were left out.\n",
    "\n",
    "### The Model <a class=\"anchor\" id=\"t25\"></a>\n",
    "\n",
    "To assess performance, we created a toy model using a simple LSTM with 5-step memory to predict the load at a specific traffic station. The input includes the precedings data of the load, the rainfall, the hour and day of the week. The results for a single station seem quite positive as can be seen in [Graph 6](#Image61). \n",
    "\n",
    "(TBD: explain the next figures a little bit: axis might be enough)\n",
    "\n",
    "<table> <a class=\"anchor\" id=\"Image61\"></a>\n",
    "    <tr>\n",
    "    <td style='text-align:center;'>\n",
    "<figure>\n",
    "<img src=\"image_source/loss_graph_p.png\">\n",
    "<figcaption style = \"text-align: center\">   <b>Figure 5:</b> Train vs Test loss plot  </figcaption>\n",
    "</figure>\n",
    " </td>\n",
    "    <td>\n",
    "<figure>\n",
    "<img src=\"image_source/fc_p.png\">\n",
    "<figcaption style = \"text-align: center\">   <b>Figure 6:</b> Traffic Forecasting for a traffic station </figcaption>\n",
    "</figure>\n",
    "            </td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9b4d07",
   "metadata": {},
   "source": [
    "## PyKX migration <a class=\"anchor\" id=\"t3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a079069-ed7c-4568-b93d-a4ffbde144c9",
   "metadata": {},
   "source": [
    "While the forecasting results obtained from the LSTM model were promising, there were certain considerations related to the efficiency of the Pythonic code used for project implementation. Firstly, the preprocessing of the datasets required an excessive amount of time. Specifically, the average time for loading and processing a month's worth of traffic information was 43.9 seconds. Similarly, the computational expenses associated with running the LSTM model for an individual station and a single month's data proved to be unfeasible within the project budget. All of these factors contributed to the team's concerns about the slowness and its potential impact on real-time data processing. Enter PyKX to the rescue! This section will detail how PyKX aided us in offloading heavy processing to kdb+/q. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513e5d34-abb3-4119-aa49-3059cc662234",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b> üîç You can find on Github the <a href=\"https://github.com/hablapps/AllRoadsLeadToPyKX/blob/Python-Version-Pre/AllRoadsLeadToPyKX.md\">Original Python Project</a> that will be migrated below into PyKX. </b>\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b624c1-374f-437e-a5a2-d02f6d9492d8",
   "metadata": {},
   "source": [
    "First of all we need to install and import PyKX:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153b6ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pykx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08e62583",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pykx as kx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf3fcd0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b> üîç A license is required to use some of the following features. You can find more information in <a href=\"https://code.kx.com/pykx/1.6/getting-started/installing.html\">\n",
    "    PyKX installation documentation</a>. </b>\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610d6e7d",
   "metadata": {},
   "source": [
    "## Datasets <a class=\"anchor\" id=\"t31\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c71b7d8-f90f-41de-956f-e56837d155f0",
   "metadata": {},
   "source": [
    "Before continuying, be sure to download the [datasets](#t21) required for running the next cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af693253",
   "metadata": {},
   "source": [
    "#### Weather"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddad2ee",
   "metadata": {},
   "source": [
    "The loading of the data will be done with the utilities provided by [PyKX](https://code.kx.com/pykx/1.4/api/read.html): (TBD: Why? It could be read as well with python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1864d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = kx.q.read.csv('../dic_meteo22.csv', types='I'*4 + '*'*4 + 'FS'*24, delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c14b39",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"background-color: #FFFFFF; border: 0px solid; padding: 0px;box-shadow: 2px 2px #3841459c; border-left: 5px solid #00b100;margin-left: 5%; margin-right: 5%;\">\n",
    "<div class=\"alert-header custom-card-header\" style=\"background-color: #d8ffd8; border: 1px solid #d8ffd8; color: black; padding: 10px; font-size: 115%;\">\n",
    "<i class=\"fa fa-commenting\" aria-hidden=\"true\" style=\"color:#00b100\"></i>&nbsp;&nbsp;&nbsp;MORE INFO: <a href=\"https://code.kx.com/pykx/1.6/api/read.html\">PyKX Read/Write Utils </a>\n",
    "</div>\n",
    "<div style=\"background-color: #e5ffdf70; ¬†padding: 40px; padding-top:30px; padding-bottom:20px\">\n",
    "<p style=\"color: black; margin-top:0%; text-align: left;margin-left: 2%; margin-right: 5%; margin-bottom: 15px;font-size: 115%; line-weight: 1.5\"> PyKX offers several functions that help loading and writing data. These functions allow you to use very different files types, both general and q-specific. The latter allows you to move tables from the q context to the Python context and vice versa.\n",
    "</p>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d9cacc",
   "metadata": {},
   "source": [
    "The parameters of the `read.csv` function are quite standard. The URL to the file and the delimiter are indicated. We highlight the *types* parameter that expects the q [types](https://code.kx.com/q/basics/datatypes/) of each column. Our table is now a PyKX object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad98ec22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pykx.wrappers.Table"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f633b7",
   "metadata": {},
   "source": [
    "Let's look at the first few rows of this table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cfb0a118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROVINCIA MUNICIPIO ESTACION MAGNITUD PUNTO_MUESTREO   ANO    MES  DIA  H01  ..\n",
      "-----------------------------------------------------------------------------..\n",
      "28        79        108      81       \"28079108_81_98\" \"2022\" \"12\" \"22\" 270  ..\n",
      "28        79        108      82       \"28079108_82_98\" \"2022\" \"12\" \"22\" 9    ..\n",
      "28        79        108      83       \"28079108_83_98\" \"2022\" \"12\" \"22\" 94.7 ..\n"
     ]
    }
   ],
   "source": [
    "print(weather[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e25b8a5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"background-color: #FFFFFF; border: 0px solid; padding: 0px;box-shadow: 2px 2px #3841459c; border-left: 5px solid #00b100;margin-left: 5%; margin-right: 5%;\">\n",
    "<div class=\"alert-header custom-card-header\" style=\"background-color: #d8ffd8; border: 1px solid #d8ffd8; color: black; padding: 10px; font-size: 115%;\">\n",
    "<i class=\"fa fa-commenting\" aria-hidden=\"true\" style=\"color:#00b100\"></i>&nbsp;&nbsp;&nbsp;MORE INFO: <a href=\"https://code.kx.com/pykx/1.6/user-guide/fundamentals/indexing.html\">Use pythonic indexing </a>\n",
    "</div>\n",
    "<div style=\"background-color: #e5ffdf70; ¬†padding: 40px; padding-top:30px; padding-bottom:20px\">\n",
    "<p style=\"color: black; margin-top:0%; text-align: left;margin-left: 2%; margin-right: 5%; margin-bottom: 15px;font-size: 115%;line-weight: 1.5\"> Accessing data from PyKX objects such as lists or tables can be done similarly to Numpy or Pandas. It allows us to index PyKX objects without the need to explicitly use q functions. And we can even index by columns! </p>        \n",
    "<code style=\"background-color: #eee;border: 1px solid #999;display: block;padding: 10px;margin-left: 5%;margin-right: 10%;margin-bottom: 0px; color:black\"> >>> print(weather[\"H01\"][:3]) \n",
    "<div style=\"color:#808080;display:inline;\"> 270 9 94.7 </div></code><br>   \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e727a69",
   "metadata": {},
   "source": [
    "We can pass the table to Pandas to see it in the markdown format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "112f77e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROVINCIA</th>\n",
       "      <th>MUNICIPIO</th>\n",
       "      <th>ESTACION</th>\n",
       "      <th>MAGNITUD</th>\n",
       "      <th>PUNTO_MUESTREO</th>\n",
       "      <th>ANO</th>\n",
       "      <th>MES</th>\n",
       "      <th>DIA</th>\n",
       "      <th>H01</th>\n",
       "      <th>V01</th>\n",
       "      <th>...</th>\n",
       "      <th>H20</th>\n",
       "      <th>V20</th>\n",
       "      <th>H21</th>\n",
       "      <th>V21</th>\n",
       "      <th>H22</th>\n",
       "      <th>V22</th>\n",
       "      <th>H23</th>\n",
       "      <th>V23</th>\n",
       "      <th>H24</th>\n",
       "      <th>V24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>108</td>\n",
       "      <td>81</td>\n",
       "      <td>b'28079108_81_98'</td>\n",
       "      <td>b'2022'</td>\n",
       "      <td>b'12'</td>\n",
       "      <td>b'22'</td>\n",
       "      <td>270.0</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>218.0</td>\n",
       "      <td>V</td>\n",
       "      <td>228.0</td>\n",
       "      <td>V</td>\n",
       "      <td>227.83</td>\n",
       "      <td>V</td>\n",
       "      <td>213.67</td>\n",
       "      <td>V</td>\n",
       "      <td>233.83</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>108</td>\n",
       "      <td>82</td>\n",
       "      <td>b'28079108_82_98'</td>\n",
       "      <td>b'2022'</td>\n",
       "      <td>b'12'</td>\n",
       "      <td>b'22'</td>\n",
       "      <td>9.0</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>V</td>\n",
       "      <td>10.0</td>\n",
       "      <td>V</td>\n",
       "      <td>9.00</td>\n",
       "      <td>V</td>\n",
       "      <td>9.00</td>\n",
       "      <td>V</td>\n",
       "      <td>8.00</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>79</td>\n",
       "      <td>108</td>\n",
       "      <td>83</td>\n",
       "      <td>b'28079108_83_98'</td>\n",
       "      <td>b'2022'</td>\n",
       "      <td>b'12'</td>\n",
       "      <td>b'22'</td>\n",
       "      <td>94.7</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>86.7</td>\n",
       "      <td>V</td>\n",
       "      <td>91.4</td>\n",
       "      <td>V</td>\n",
       "      <td>93.80</td>\n",
       "      <td>V</td>\n",
       "      <td>96.30</td>\n",
       "      <td>V</td>\n",
       "      <td>98.70</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PROVINCIA  MUNICIPIO  ESTACION  MAGNITUD     PUNTO_MUESTREO      ANO  \\\n",
       "0         28         79       108        81  b'28079108_81_98'  b'2022'   \n",
       "1         28         79       108        82  b'28079108_82_98'  b'2022'   \n",
       "2         28         79       108        83  b'28079108_83_98'  b'2022'   \n",
       "\n",
       "     MES    DIA    H01 V01  ...    H20 V20    H21 V21     H22 V22     H23 V23  \\\n",
       "0  b'12'  b'22'  270.0   N  ...  218.0   V  228.0   V  227.83   V  213.67   V   \n",
       "1  b'12'  b'22'    9.0   N  ...   10.0   V   10.0   V    9.00   V    9.00   V   \n",
       "2  b'12'  b'22'   94.7   N  ...   86.7   V   91.4   V   93.80   V   96.30   V   \n",
       "\n",
       "      H24 V24  \n",
       "0  233.83   V  \n",
       "1    8.00   V  \n",
       "2   98.70   V  \n",
       "\n",
       "[3 rows x 56 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather[:3].pd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a18428f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"background-color: #FFFFFF; border: 0px solid; padding: 0px;box-shadow: 2px 2px #3841459c; border-left: 5px solid #00b100;margin-left: 5%; margin-right: 5%;\">\n",
    "<div class=\"alert-header custom-card-header\" style=\"background-color: #d8ffd8; border: 1px solid #d8ffd8; color: black; padding: 10px; font-size: 115%;\">\n",
    "<i class=\"fa fa-commenting\" aria-hidden=\"true\" style=\"color:#00b100\"></i>&nbsp;&nbsp;&nbsp;MORE INFO: Use <a href=\"https://code.kx.com/pykx/1.6/user-guide/fundamentals/creating.html\">Python/Q Transform</a> \n",
    "</div>\n",
    "<div style=\"background-color: #e5ffdf70; ¬†padding: 40px; padding-top:30px; padding-bottom:20px\">\n",
    "<p style=\"color: black; margin-top:0%; text-align: left;margin-left: 2%; margin-right: 5%; margin-bottom: 15px;font-size: 115%; line-weight: 1.5\"> Objects from q can be converted to pandas with <code>.pd()</code>, to PyArrow with <code>.pa()</code>, to numpy with <code>.np()</code> and to Python with <code>.py()</code> methods. And then back to q so that colleagues can continue the work with PyKX objects with <code>toq(pyObject)</code> function. This is great for Python developers new to PyKX because it allows them to take advantage of kdb+ databases while learning q.</p>        \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2471fa81",
   "metadata": {},
   "source": [
    "As we can see, it's not inside the q memory space. Let's see how to access these objects and how to use q features on them. Let's start with the simple `xcol` function, which allows us to rename columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a8218145",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = kx.q.xcol({'ANO': 'year', 'MES': 'month', 'DIA': 'day', 'ESTACION':'weather_station', 'MAGNITUD':'magnitude'}, weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4292779",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"background-color: #FFFFFF; border: 0px solid; padding: 0px;box-shadow: 2px 2px #3841459c; border-left: 5px solid #00b100;margin-left: 5%; margin-right: 5%;\">\n",
    "<div class=\"alert-header custom-card-header\" style=\"background-color: #d8ffd8; border: 1px solid #d8ffd8; color: black; padding: 10px; font-size: 115%;\">\n",
    "<i class=\"fa fa-commenting\" aria-hidden=\"true\" style=\"color:#00b100\"></i>&nbsp;&nbsp;&nbsp;MORE INFO: <a href=\"https://code.kx.com/pykx/1.6/user-guide/fundamentals/evaluating.html\">Use q functions </a>\n",
    "</div>\n",
    "<div style=\"background-color: #e5ffdf70; ¬†padding: 40px; padding-top:30px; padding-bottom:20px\">\n",
    "<p style=\"color: black; margin-top:0%; text-align: left;margin-left: 2%; margin-right: 5%; margin-bottom: 15px;font-size: 115%; line-weight: 1.5\"> Many q functions are available through the <code>pykx.q</code> interface. The attributes are identical to those expected in the q function but using Python structures instead. These functions are compiled and perfectly explained in the <a href=\"https://code.kx.com/pykx/1.6/api/q/q.html\"> PyKX documentation</a></p>\n",
    "<code style=\"background-color: #eee;border: 1px solid #999;display: block;padding: 10px;margin-left: 5%;margin-right: 10%; color:black\"> >>> kx.q.distinct(['A', 'B', 'B', 'B' ,'C'])\n",
    "<div style=\"color:#808080;display:inline;\"> `A`B`C </div></code><br> \n",
    "<p style=\"color: black; margin-top:0%; text-align: left;margin-left: 2%; margin-right: 5%; margin-bottom: 15px;font-size: 115%; line-weight: 1.5\"> For those who want to dig deeper into kdb+/q and gain experience, you can use q functions and pass PyKX objects as arguments: </p>\n",
    "<code style=\"background-color: #eee;border: 1px solid #999;display: block;padding: 10px;margin-left: 5%;margin-right: 10%; color:black\"> >>> kx.q(\"distinct\", ['A', 'B', 'B', 'B' ,'C'])\n",
    "<div style=\"color:#808080;display:inline;\"> `A`B`C </div></code><br> \n",
    "<p style=\"color: black; margin-top:0%; text-align: left;margin-left: 2%; margin-right: 5%; margin-bottom: 15px;font-size: 115%; line-weight: 1.5\"> Note that in the previous function a Python object is being passed to a q function. If Python objects have a direct equivalent in q, such as dictionaries, they can be directly used as the attributes for PyKX functions. Underneath, PyKX takes care of transforming it to q. </p>\n",
    "<p style=\"color: black; margin-top:0%; text-align: left;margin-left: 2%; margin-right: 5%; margin-bottom: 15px;font-size: 115%; line-weight: 1.5\"> You can also apply <a href=\"https://code.kx.com/q/basics/iteration/\">q iterations</a> to functions: </p>\n",
    "<code style=\"background-color: #eee;border: 1px solid #999;display: block;padding: 10px;margin-left: 5%;margin-right: 10%; color:black\"> >>> kx.q(\"lower\").each(['A', 'B', 'C'])\n",
    "<div style=\"color:#808080;display:inline;\"> `a`b`c </div></code><br>   \n",
    "<p style=\"color: black; margin-top:0%; text-align: left;margin-left: 2%; margin-right: 5%; margin-bottom: 15px;font-size: 115%; line-weight: 1.5\"> Finally, you can even create functions and use them with PyKX or Python objects.</p>\n",
    "<code style=\"background-color: #eee;border: 1px solid #999;display: block;padding: 10px;margin-left: 5%;margin-right: 10%; color:black\"> >>> kx.q(\"{u !(sum x=) each u:distinct x}\", ['A', 'B', 'B', 'B' ,'C'])\n",
    "<div style=\"color:#808080;display:inline;\"> A| 1\n",
    " B| 3\n",
    " C| 1 </div></code><br>   \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d697002e",
   "metadata": {},
   "source": [
    "Apart from this functions we have the `kx.q.qsql` interface, which allows us to query into tables. Specifically we can use `select`, `exec`, `update` and `delete`, which share some common characteristics, mainly with the arguments they receive.\n",
    "\n",
    "The first three share roughly this function call structure:\n",
    "\n",
    "`kx.q.qsql.{function}({tab}, columns=..., where=..., by=...)`\n",
    "\n",
    "The `columns` argument expects either a list of strings or a dictionary where the key is the column name and the value is the actual value you want in this column if let's say you want to apply a function to it. Let's look at this specific example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "84147904",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = kx.q.qsql.delete(weather, ['PUNTO_MUESTREO', 'PROVINCIA', 'MUNICIPIO'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d303c62",
   "metadata": {},
   "source": [
    "With the above code we have removed several columns that are not relevant to the analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bb0730",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"background-color: #FFFFFF; border: 0px solid; padding: 0px;box-shadow: 2px 2px #3841459c; border-left: 5px solid #00b100;margin-left: 5%; margin-right: 5%;\">\n",
    "<div class=\"alert-header custom-card-header\" style=\"background-color: #d8ffd8; border: 1px solid #d8ffd8; color: black; padding: 10px; font-size: 115%;\">\n",
    "<i class=\"fa fa-commenting\" aria-hidden=\"true\" style=\"color:#00b100\"></i>&nbsp;&nbsp;&nbsp;MORE INFO: <a href=\"https://code.kx.com/pykx/1.6/api/read.html\">qSQL</a> and  <a href=\"https://code.kx.com/pykx/1.6/api/read.html\">SQL</a> querys\n",
    "</div>\n",
    "<div style=\"background-color: #e5ffdf70; ¬†padding: 40px; padding-top:30px; padding-bottom:20px\">\n",
    "<p style=\"color: black; margin-top:0%; text-align: left;margin-left: 2%; margin-right: 5%; margin-bottom: 15px;font-size: 115%; line-weight: 1.5\"> qSQL queries are very powerful and concise at the same time. As we have seen PyKX allows you to use qSQL queries using API functions.</p>\n",
    "<code style=\"background-color: #eee;border: 1px solid #999;display: block;padding: 10px;margin-left: 5%;margin-right: 10%; color:black\"> >>> print(kx.q.qsql.select(weather, {\"magnitude\": \"count distinct magnitude\"}, by=[\"weather_station\"])[:3])\n",
    "<br><div style=\"color:#808080;display:inline;\"> weather_station| magnitude\n",
    " ---------------| ---------\n",
    " 4 ¬† ¬† ¬† ¬† ¬† ¬† ¬†| 1 ¬† ¬† ¬† ¬†\n",
    " 8 ¬† ¬† ¬† ¬† ¬† ¬† ¬†| 2 ¬† ¬† ¬† ¬†\n",
    " 16 ¬† ¬† ¬† ¬† ¬† ¬† | 2 ¬† ¬† \n",
    "</div>¬† ¬† ¬† ¬† ¬†\n",
    "</code>\n",
    "<br>\n",
    "<p style=\"color: black; margin-top:0%; text-align: left;margin-left: 2%; margin-right: 5%; margin-bottom: 15px;font-size: 115%; line-weight: 1.5\"> But if you are more familiar with the q environment it is also possible to use q functions. This reduces the verbosity of python functions.\n",
    "</p>\n",
    "<code style=\"background-color: #eee;border: 1px solid #999;display: block;padding: 10px;margin-left: 5%;margin-right: 10%; color:black\"> >>> print(kx.q(\"{select count distinct magnitude by weather_station from x}\", weather)[:3])\n",
    "<br> <div style=\"color:#808080;display:inline;\">weather_station| magnitude\n",
    " ---------------| ---------\n",
    " 4 ¬† ¬† ¬† ¬† ¬† ¬† ¬†| 1 ¬† ¬† ¬† ¬†\n",
    " 8 ¬† ¬† ¬† ¬† ¬† ¬† ¬†| 2 ¬† ¬† ¬† ¬†\n",
    " 16 ¬† ¬† ¬† ¬† ¬† ¬† | 2 \n",
    "</div> ¬† ¬†\n",
    "</code>\n",
    "<br>\n",
    "<p style=\"color: black; margin-top:0%; text-align: left;margin-left: 2%; margin-right: 5%; margin-bottom: 15px;font-size: 115%; line-weight: 1.5\"> PyKX lets you use SQL queries too! </p>\n",
    "<code style=\"background-color: #eee;border: 1px solid #999;display: block;padding: 10px;margin-left: 5%;margin-right: 10%; color:black\"> >>> print(kx.q.sql(\"SELECT weather_station, COUNT(DISTINCT(magnitude)) FROM &#36 1 GROUP BY weather_station\", weather)[:3])\n",
    "<br> <div style=\"color:#808080;display:inline;\">weather_station magnitude\n",
    " -------------------------\n",
    " 4 ¬† ¬† ¬† ¬† ¬† ¬† ¬† 1 ¬† ¬† ¬† ¬†\n",
    " 8 ¬† ¬† ¬† ¬† ¬† ¬† ¬† 2 ¬† ¬† ¬† ¬†\n",
    " 16 ¬† ¬† ¬† ¬† ¬† ¬† ¬†2 ¬† ¬† ¬† ¬†¬† ¬† ¬†\n",
    "</div></code>\n",
    "<br>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918d5bf5",
   "metadata": {},
   "source": [
    "The next task we need to do is combine the year, month, and day into a single date column. To do this, we started by accessing these three columns. This can be done by indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eb4b9390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"2022\" \"2022\" \"2022\" \"2022\" \"2022\" \"2022\" \"2022\" \"2022\" \"2022\" \"2022\" \"2022\" ..\n",
      "\"12\"   \"12\"   \"12\"   \"12\"   \"12\"   \"12\"   \"12\"   \"12\"   \"12\"   \"12\"   \"12\"   ..\n",
      "\"22\"   \"22\"   \"22\"   \"22\"   \"22\"   \"22\"   \"22\"   \"01\"   \"02\"   \"03\"   \"04\"   ..\n"
     ]
    }
   ],
   "source": [
    "print(weather[\"year\", \"month\", \"day\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26c28f9",
   "metadata": {},
   "source": [
    "We see that the result is three lists of the sample size. Our goal is a list of sample size with the three elements that make up the date joined together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f5bd22de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"2022\" \"12\" \"22\"\n",
      "\"2022\" \"12\" \"22\"\n",
      "\"2022\" \"12\" \"22\"\n"
     ]
    }
   ],
   "source": [
    "print(kx.q.flip(weather[\"year\", \"month\", \"day\"])[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e8840b",
   "metadata": {},
   "source": [
    "Looks like we're getting clos. Now we have a sample size list with a list in each position containing 3 elements: the day, the month and the year. To join each set of the list into a single joined element, the *each* iterator can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "42039622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"20221222\"\n",
      "\"20221222\"\n",
      "\"20221222\"\n"
     ]
    }
   ],
   "source": [
    "print(kx.q.each(kx.q.raze, kx.q.flip(weather[\"year\", \"month\", \"day\"]))[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548e17b7",
   "metadata": {},
   "source": [
    "All that remains to do is to convert it from string to date. Unfortunately, some functions (especially the overloaded glyphs) are not yet implemented. For example cast (`$`), take (`#`), concat (`,`)... So we are forced to abandon pythonic way of calling q functions and perform this casting writing kdb+/q code using the pykx.q method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1cf09e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022.12.22 2022.12.22 2022.12.22\n"
     ]
    }
   ],
   "source": [
    "date = kx.q('\"D\"$',(kx.q.each(kx.q.raze, kx.q.flip(weather[\"year\", \"month\", \"day\"]))))\n",
    "print(date[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb59c9e",
   "metadata": {},
   "source": [
    "Finally, we add this column to our table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "191fd7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_ = kx.q.qsql.update(weather, columns = {'date': date})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e28fba3",
   "metadata": {},
   "source": [
    "Some team members started using q code instead of PyKX functions in the pythonic way, as they found the resulting code to be more elegant and concise. Once the team had a little more fluency, a function written entirely in q was proposed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2b17e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = kx.q.qsql.update(weather, columns = {'date':'\"D\"$ raze each flip(year;month;day)'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489d45fc",
   "metadata": {},
   "source": [
    "Again, both solutions are fully compatible, even combinable. It is up to the programmer to use one methodology or the other. \n",
    "\n",
    "The three columns that are already included in date can now be removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6f26aa8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = kx.q.qsql.delete(weather, ['year', 'month', 'day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ed733a",
   "metadata": {},
   "source": [
    "The current state of the weather table is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "17801c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weather_station</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>H01</th>\n",
       "      <th>V01</th>\n",
       "      <th>H02</th>\n",
       "      <th>V02</th>\n",
       "      <th>H03</th>\n",
       "      <th>V03</th>\n",
       "      <th>H04</th>\n",
       "      <th>V04</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>H21</th>\n",
       "      <th>V21</th>\n",
       "      <th>H22</th>\n",
       "      <th>V22</th>\n",
       "      <th>H23</th>\n",
       "      <th>V23</th>\n",
       "      <th>H24</th>\n",
       "      <th>V24</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>81</td>\n",
       "      <td>270.0</td>\n",
       "      <td>N</td>\n",
       "      <td>252.0</td>\n",
       "      <td>N</td>\n",
       "      <td>216.0</td>\n",
       "      <td>N</td>\n",
       "      <td>242.0</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>V</td>\n",
       "      <td>228.0</td>\n",
       "      <td>V</td>\n",
       "      <td>227.83</td>\n",
       "      <td>V</td>\n",
       "      <td>213.67</td>\n",
       "      <td>V</td>\n",
       "      <td>233.83</td>\n",
       "      <td>V</td>\n",
       "      <td>2022-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108</td>\n",
       "      <td>82</td>\n",
       "      <td>9.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>N</td>\n",
       "      <td>9.0</td>\n",
       "      <td>N</td>\n",
       "      <td>8.0</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>V</td>\n",
       "      <td>10.0</td>\n",
       "      <td>V</td>\n",
       "      <td>9.00</td>\n",
       "      <td>V</td>\n",
       "      <td>9.00</td>\n",
       "      <td>V</td>\n",
       "      <td>8.00</td>\n",
       "      <td>V</td>\n",
       "      <td>2022-12-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108</td>\n",
       "      <td>83</td>\n",
       "      <td>94.7</td>\n",
       "      <td>N</td>\n",
       "      <td>97.6</td>\n",
       "      <td>N</td>\n",
       "      <td>96.6</td>\n",
       "      <td>N</td>\n",
       "      <td>97.5</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>V</td>\n",
       "      <td>91.4</td>\n",
       "      <td>V</td>\n",
       "      <td>93.80</td>\n",
       "      <td>V</td>\n",
       "      <td>96.30</td>\n",
       "      <td>V</td>\n",
       "      <td>98.70</td>\n",
       "      <td>V</td>\n",
       "      <td>2022-12-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows √ó 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   weather_station  magnitude    H01 V01    H02 V02    H03 V03    H04 V04  \\\n",
       "0              108         81  270.0   N  252.0   N  216.0   N  242.0   N   \n",
       "1              108         82    9.0   N    8.0   N    9.0   N    8.0   N   \n",
       "2              108         83   94.7   N   97.6   N   96.6   N   97.5   N   \n",
       "\n",
       "   ...  V20    H21  V21     H22  V22     H23  V23     H24  V24       date  \n",
       "0  ...    V  228.0    V  227.83    V  213.67    V  233.83    V 2022-12-22  \n",
       "1  ...    V   10.0    V    9.00    V    9.00    V    8.00    V 2022-12-22  \n",
       "2  ...    V   91.4    V   93.80    V   96.30    V   98.70    V 2022-12-22  \n",
       "\n",
       "[3 rows x 51 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather[:3].pd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e5605b",
   "metadata": {},
   "source": [
    "Now it's time to turn our attention to breaking down the H* and V* queries into multiple rows, and supplying a time column to avoid missing information. The way to proceed in q would be to use functional qSQL to select the columns that follow the previous patterns, but we are going to take advantage of the fact that the q code in PyKX is introduced through strings to avoid it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6593753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def functionalSearch(cols, pattern, func):\n",
    "    xcols = cols[kx.q.where(kx.q.like(cols, pattern))]\n",
    "    xstring = func.format(kx.q.sv(b\";\", kx.q.string(xcols)).py().decode(\"utf-8\"))\n",
    "    return xcols, xstring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d8b1c2",
   "metadata": {},
   "source": [
    "The above function receives a list of columns, a pattern to search for, and a q function in string format that passes as an argument the columns found following that pattern in qSQL format (where columns are accessed with their names and not with a symbol). Applying this to all columns starting with *\"H\"* returns these columns as a vector of symbols and a string of these columns in qSQL format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2cf4a815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns found:  `H01`H02`H03`H04`H05`H06`H07`H08`H09`H10`H11`H12`H13`H14`H15`H16`H17`H18`H19`..\n",
      "qSQL function:  H01;H02;H03;H04;H05;H06;H07;H08;H09;H10;H11;H12;H13;H14;H15;H16;H17;H18;H19;H20;H21;H22;H23;H24\n"
     ]
    }
   ],
   "source": [
    "cols = kx.q.cols(weather)\n",
    "found_columns, qsql_function = functionalSearch(cols, b'H*', \"{}\")\n",
    "\n",
    "print(\"Columns found: \", found_columns)\n",
    "print(\"qSQL function: \", qsql_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480bbd90",
   "metadata": {},
   "source": [
    "This is very powerful, as it allows us to use qSQL with variables without having to use functional forms (usually complicated for first-time kdb/q developers)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647b08d1",
   "metadata": {},
   "source": [
    "Let's use the above for the columns beginning with **H**, which will give us the measurement value; and the columns that begin with **V**, which tell us if the measurement is valid or not. The function to convert the measurements column to rows is *flip*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e908afdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hcols, value = functionalSearch(cols, b'H*', \"flip({})\")\n",
    "vcols, valid = functionalSearch(cols, b'V*', \"flip({})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a313364b",
   "metadata": {},
   "source": [
    "Now we just have to pass our built-in functions in string format to the qSQL \"update\" function, together with the 24 hours repeated the initial number of rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "31e2a2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = kx.q.qsql.update(weather, columns = {'hour': 'count[i]#enlist 01:00*til 24', 'values': value, 'valid': valid})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38db750d",
   "metadata": {},
   "source": [
    "Columns starting with **H** or **V** can be removed by using the same trick we used before to prevent functional qSQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2fbf8b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = kx.q.qsql.delete(weather, columns = kx.q.raze(hcols,vcols).py())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99ffb55",
   "metadata": {},
   "source": [
    "Let's see the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "47841c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weather_station</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>date</th>\n",
       "      <th>hour</th>\n",
       "      <th>values</th>\n",
       "      <th>valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>81</td>\n",
       "      <td>2022-12-22</td>\n",
       "      <td>[0 minutes, 60 minutes, 120 minutes, 180 minut...</td>\n",
       "      <td>[270.0, 252.0, 216.0, 242.0, 239.0, 246.0, 233...</td>\n",
       "      <td>[N, N, N, N, N, N, N, N, N, N, V, V, V, V, V, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108</td>\n",
       "      <td>82</td>\n",
       "      <td>2022-12-22</td>\n",
       "      <td>[0 minutes, 60 minutes, 120 minutes, 180 minut...</td>\n",
       "      <td>[9.0, 8.0, 9.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, ...</td>\n",
       "      <td>[N, N, N, N, N, N, N, N, N, N, V, V, V, V, V, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108</td>\n",
       "      <td>83</td>\n",
       "      <td>2022-12-22</td>\n",
       "      <td>[0 minutes, 60 minutes, 120 minutes, 180 minut...</td>\n",
       "      <td>[94.7, 97.6, 96.6, 97.5, 97.5, 98.2, 98.8, 98....</td>\n",
       "      <td>[N, N, N, N, N, N, N, N, N, N, V, V, V, V, V, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weather_station  magnitude       date  \\\n",
       "0              108         81 2022-12-22   \n",
       "1              108         82 2022-12-22   \n",
       "2              108         83 2022-12-22   \n",
       "\n",
       "                                                hour  \\\n",
       "0  [0 minutes, 60 minutes, 120 minutes, 180 minut...   \n",
       "1  [0 minutes, 60 minutes, 120 minutes, 180 minut...   \n",
       "2  [0 minutes, 60 minutes, 120 minutes, 180 minut...   \n",
       "\n",
       "                                              values  \\\n",
       "0  [270.0, 252.0, 216.0, 242.0, 239.0, 246.0, 233...   \n",
       "1  [9.0, 8.0, 9.0, 8.0, 8.0, 8.0, 8.0, 8.0, 8.0, ...   \n",
       "2  [94.7, 97.6, 96.6, 97.5, 97.5, 98.2, 98.8, 98....   \n",
       "\n",
       "                                               valid  \n",
       "0  [N, N, N, N, N, N, N, N, N, N, V, V, V, V, V, ...  \n",
       "1  [N, N, N, N, N, N, N, N, N, N, V, V, V, V, V, ...  \n",
       "2  [N, N, N, N, N, N, N, N, N, N, V, V, V, V, V, ...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather[:3].pd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d972de",
   "metadata": {},
   "source": [
    "Now all we have to do is expand the table so that each element of the lists corresponds to a row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fb74c354",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = kx.q.ungroup(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8936d724",
   "metadata": {},
   "source": [
    "We can shrink the table a bit more by removing the rows that are not valid and joining the date with the time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bc57be57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weather_station</th>\n",
       "      <th>magnitude</th>\n",
       "      <th>date</th>\n",
       "      <th>values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>81</td>\n",
       "      <td>2022-12-22 10:00:00</td>\n",
       "      <td>263.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108</td>\n",
       "      <td>81</td>\n",
       "      <td>2022-12-22 11:00:00</td>\n",
       "      <td>247.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108</td>\n",
       "      <td>81</td>\n",
       "      <td>2022-12-22 12:00:00</td>\n",
       "      <td>215.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   weather_station  magnitude                date  values\n",
       "0              108         81 2022-12-22 10:00:00  263.00\n",
       "1              108         81 2022-12-22 11:00:00  247.83\n",
       "2              108         81 2022-12-22 12:00:00  215.83"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = kx.q.qsql.select(weather, where = 'valid=`V')\n",
    "weather = kx.q.qsql.update(weather, columns = {'date': 'date+hour'})\n",
    "weather = kx.q.qsql.delete(weather, columns = [\"valid\", \"hour\"])\n",
    "weather[:3].pd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71a09f9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"background-color: #FFFFFF; border: 0px solid; padding: 0px;box-shadow: 2px 2px #3841459c; border-left: 5px solid #00b100;margin-left: 5%; margin-right: 5%;\">\n",
    "<div class=\"alert-header custom-card-header\" style=\"background-color: #d8ffd8; border: 1px solid #d8ffd8; color: black; padding: 10px; font-size: 115%;\">\n",
    "<i class=\"fa fa-commenting\" aria-hidden=\"true\" style=\"color:#00b100\"></i>&nbsp;&nbsp;&nbsp;ALTERNATIVE FEATURE: Use <a href=\"https://code.kx.com/pykx/1.6/user-guide/advanced/numpy.html\">Numpy</a> and  <a href=\"https://code.kx.com/pykx/1.6/user-guide/advanced/Pandas_API.html\">Pandas</a>\n",
    "</div>\n",
    "<div style=\"background-color: #e5ffdf70; ¬†padding: 40px; padding-top:30px; padding-bottom:20px\">\n",
    "<p style=\"color: black; margin-top:0%; text-align: left;margin-left: 2%; margin-right: 5%; margin-bottom: 15px;font-size: 115%;line-weight: 1.5\"> Those of us who are not yet so familiar with the kdb+/q ecosystem, we can continue using part of Numpy's functionality. Specifically   <a href=\"https://numpy.org/doc/stable/reference/ufuncs.html\">universal functions</a>. Using this type of function, the mean of an array can be coded as:</p> \n",
    "<code style=\"background-color: #eee;border: 1px solid #999;display: block;padding: 10px;margin-left: 5%;margin-right: 10%;color:black\"> >>> import numpy as np\n",
    " >>>\n",
    " >>> def numpy_mean(arr):\n",
    " >>>   return np.add.reduce(arr) / len(arr)\n",
    " >>>\n",
    " >>> print(numpy_mean(kx.toq([1,4,6,7,9])))    \n",
    "<div style=\"color:#808080;display:inline;\">5.4 </div></code><br>\n",
    "<p style=\"color: black; margin-top:0%; text-align: left;margin-left: 2%; margin-right: 5%; margin-bottom: 15px;font-size: 115%; line-weight: 1.5\"> Pandas can be used with PyKX objects using the Pandas API. It can be used simply by importing Numpy and Pandas and activating a flag. The Pandas API is still in the development phase, so it does not have all the functions of Pandas implemented yet. </p>     \n",
    "<code style=\"background-color: #eee;border: 1px solid #999;display: block;padding: 10px;margin-left: 5%;margin-right: 10%;color:black\"> >>> import os\n",
    " >>> os.environ['PYKX_ENABLE_PANDAS_API'] = 'true'\n",
    " >>> import numpy as np\n",
    " >>> import pandas as pd\n",
    " >>>\n",
    " >>> print(weather.iloc[weather[\"magnitude\"] == \"temperature\", [\"magnitude\", \"values\"]][:5])        \n",
    "<br> <div style=\"color:#808080;display:inline;\"> magnitude   | values\n",
    "  ------------| ---------\n",
    "  temperature | 7.1  ¬† ¬† ¬† ¬†\n",
    "  temperature | 6.6 ¬† ¬† ¬† ¬†\n",
    "  temperature | 6.0 ¬† ¬†\n",
    "</div></code>\n",
    "<br>\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84958976",
   "metadata": {},
   "source": [
    "The **magnitude** column is required to give semantics to the **value**. As established by the dataset creators, the different magnitudes correspond to the items that we collect in the following dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f55f17e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "magnitude = {80:\"ultraviolet\", \n",
    "             81:\"wind\", \n",
    "             82:\"direction\", \n",
    "             83:\"temperature\", \n",
    "             86:\"humidity\", \n",
    "             87:\"pressure\", \n",
    "             88:\"solar\", \n",
    "             89:\"rainfall\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f326a7fb",
   "metadata": {},
   "source": [
    "We just have to change the key by the value of the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "283b8af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = kx.q('{update magnitude: x magnitude from y}', magnitude, weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf23dc76",
   "metadata": {},
   "source": [
    "Finally, all you have to do is separate the different weather conditions into different columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "71c89fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = kx.q('{exec (value x)#magnitude!values by date,weather_station from y}',magnitude,weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a655a33d-5c25-4000-82c5-c8e3f440bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (TBD: show some sample records of the table after each major transformation stage. For instance, here. But weather[:3].pd() doesn't work)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1f12f2",
   "metadata": {},
   "source": [
    "The exec query allows us to convert a dictionary stored in a column into multiple columns with the key as the column name and the values as the data in that column. This is useful when we create a dictionary made up of the weather conditions of each row associated with their values. By applying it and grouping we have the weather conditions in different columns for each weather entry and weather station."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc6752c",
   "metadata": {},
   "source": [
    "#### Traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca26a67",
   "metadata": {},
   "source": [
    "This second table will also be loaded into the Python environment (TBD: more specifically, in the Q environment within Python?):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b91f9f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = kx.q.read.csv('../12-2022.csv', types=\"IPSIIIISI\", delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aa150a",
   "metadata": {},
   "source": [
    "We are interested in knowing the average load by date and by season, removing measurement errors. The power of qSQL allows us to do this in a single query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "18fd845d",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = kx.q.qsql.select(traffic,\n",
    "                         columns = {'traffic_load': 'avg carga'},\n",
    "                         by = {\"date\":'fecha', \"traffic_station\": 'id'}, \n",
    "                         where = \"error=`N\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d370ea1-0370-4e27-9012-f8481cd706bb",
   "metadata": {},
   "source": [
    "(TBD: show samples of the traffic table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639ec322",
   "metadata": {},
   "source": [
    "#### Location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73df10e6",
   "metadata": {},
   "source": [
    "Both traffic and weather station tables will be loaded into the q memory space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9466bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "kx.q[\"weather_station\"] = kx.q.read.csv('../Estaciones_control_datos_meteorologicos.csv', types=\" IFF\", delimiter=\";\", as_table=True)\n",
    "kx.q[\"traffic_station\"] = kx.q.read.csv('../pmed_ubicacion_04-2023.csv', types = \"SII**FFFF\", delimiter = \";\", as_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d877080b",
   "metadata": {},
   "source": [
    "We can now access these objects within q functions without needing to pass them as PyKX or Python objects. For example, let's change the name of the columns in both tables to standardize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51b35d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "kx.q(\"weather_station:(`CODIGO_CORTO`LONGITUD`LATITUD!`weather_station`longitude`latitude)xcol weather_station\")\n",
    "_=kx.q(\"traffic_station:(`id`longitud`latitud!`traffic_station`longitude`latitude)xcol traffic_station\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1451b6b5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"background-color: #FFFFFF; border: 0px solid; padding: 0px;box-shadow: 2px 2px #3841459c; border-left: 5px solid #00b100;border-top: 2px solid #00b100;margin-left: 5%; margin-right: 5%;\">\n",
    "<div class=\"alert-header custom-card-header\" style=\"background-color: #d8ffd8; border: 1px solid #d8ffd8; color: black; padding: 10px; font-size: 115%;\">\n",
    "<i class=\"fa fa-commenting\" aria-hidden=\"true\" style=\"color:#00b100\"></i>&nbsp;&nbsp;&nbsp;MORE INFO: Use <a href=\"https://code.kx.com/pykx/1.6/user-guide/fundamentals/creating.html#by-retrieving-a-named-entity-from-qs-memory\">Q memory space</a> \n",
    "</div>\n",
    "<div style=\"background-color: #e5ffdf70; ¬†padding: 40px; padding-top:30px; padding-bottom:20px\">\n",
    "<p style=\"color: black; margin-top:0%; text-align: left;margin-left: 2%; margin-right: 5%; margin-bottom: 15px;font-size: 115%; line-weight: 1.5\"> If you feel more comfortable programming in q, you can work in the q memory space. PyKX objects can be passed into the q memory space to work with them as if you were in a q ecosystem like so: <code>kx.q[\"table\"]</code>. Then to bring them back to the Python memory space, you just have to return them using q code: <code>kx.q(\"table\")</code></p>       \n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de6673e-e43e-4f3d-8282-cfaa5b06924e",
   "metadata": {},
   "source": [
    "(TBD: border-top: 2px solid #00b100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3e9c38",
   "metadata": {},
   "source": [
    "Our goal is to join these two tables. There seems to be no identifier that allows us to do a standard join. However, both the weather and traffic stations are located by coordinates. We can use the distance between the stations for measuring traffic and weather to join them. To calculate the distance between two coordinates, the Harvesine distance can be used as discussed earlier. This distance function is already developed in Python but it is not available on q.\n",
    "\n",
    "One option would be to reimplement it in q, but this would not be feasible in case we were dealing with more complex libraries. Although slower, we could pass our q objects to Python and work with them. However, it is advisable to keep using q objects for as long as possible. These features we just explained for moving from Python objects to q and vice versa allow us, at least temporarily, to reuse Python code. It is also reasonable for the size of tables we are working with in this step. To introduce our q objects in this function, we can use some of the PyKX tools to transform them into Python objects that we talked about in [Learning Pykx](). (TBD: Learning PyKx no longer available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee5024c-3310-4eeb-9c87-4bc28701eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377c492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from haversine import haversine_vector, Unit\n",
    "dist = kx.toq(\n",
    "            haversine_vector(kx.q('`longitude`latitude # weather_station').pd(), \n",
    "                             kx.q('`longitude`latitude # traffic_station').pd(),\n",
    "                             Unit.KILOMETERS, comb=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fda50b",
   "metadata": {},
   "source": [
    "We now have a matrix that measures the distance in kilometers for each pair of traffic and weather stations. We can select the pairs of station identifiers whose minimum distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8755d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = kx.q.each(kx.q('{first where x=min x}'), dist)\n",
    "distance_table = kx.q('{traffic_station ^ weather_station[x]}' ,  ids)\n",
    "distance_table = kx.q.qsql.delete(distance_table, columns = ['tipo_elem','distrito','cod_cent','nombre','utm_x','utm_y','longitude', 'latitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45aea31",
   "metadata": {},
   "source": [
    "#### Final Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5999eb37",
   "metadata": {},
   "source": [
    "The joining of the three tables is fairly straightforward. The distances table can be joined with any of the other two by means of a simple left join. The traffic and weather ones have to be joined with an asof join as they have different time intervals. Finally, two columns need to be added to convey the seasonality of the data to the model: time and day of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df26283",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete = kx.q.lj(traffic, kx.q.xkey('traffic_station', distance_table))\n",
    "complete = kx.q.aj(kx.toq(['weather_station', 'date']), complete, weather)\n",
    "complete = kx.q.qsql.update(kx.q(\"0^\",complete),  {\"hour\":\"`hh$date\", \"weekday\":'(\"d\"$date)mod 7'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef26d05",
   "metadata": {},
   "source": [
    "Let's look at this last table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b172926",
   "metadata": {},
   "outputs": [],
   "source": [
    "kx.q(\"5#\",complete).pd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf47ef9",
   "metadata": {},
   "source": [
    "### Model <a class=\"anchor\" id=\"t32\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ead963",
   "metadata": {},
   "source": [
    "For the model's ingestion, we opt for the selection of only the necessary columns. Additionally, we normalize the rainfall column using a simple MinMax scaler. This function can be included within the q memory spacefor whenever it's required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb98ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kx.q(\"minMaxScale:{[l] ({(x-y)%(z-y)}[;min l;max l]')l}\")\n",
    "                  \n",
    "final = kx.q.qsql.select(complete, columns = {\"date\": \"date\",\n",
    "                                              \"traffic_station\":\"traffic_station\",\n",
    "                                              \"hour\":\"hour\", \n",
    "                                              \"weekday\": \"weekday\", \n",
    "                                              \"traffic_load\": \"traffic_load%100\", \n",
    "                                              \"temperature\":\"minMaxScale temperature\", \n",
    "                                              \"rainfall\":\"minMaxScale rainfall\"}\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad90de90",
   "metadata": {},
   "source": [
    "During this migration from Pandas, the main hassle was to migrate the `time_window` function, as it relied on loops. The way we approached it was to first understand the input we had, the output we needed and then think of an idiomatic way to implement it using q instead of doing a 1:1 migration, which would have probably be more costly in terms of time. In this case, our input was a table and our output was a list of matrices for each station. We created several functions that helped us during the process:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2380c45",
   "metadata": {},
   "source": [
    "* **sliding window**: given a matrix, x, divides it into chunks of length y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52efb25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_=kx.q(\"\"\"sw:{({y#z _x}[x;y;]')til count b:y _x}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffbd8f1",
   "metadata": {},
   "source": [
    "* **get target**: For a given matrix, x, it takes the target located in the column z and the first lines are eliminated to match with the chunks length y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db63415",
   "metadata": {},
   "outputs": [],
   "source": [
    "_=kx.q(\"\"\"gt:{y _(flip x)[z]}\"\"\") # gets target (in position z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc28810",
   "metadata": {},
   "source": [
    "* **to Matrix**: Transform the table x to a matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba717a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "_=kx.q(\"\"\"toMatrix:{({[t;i]value t[i]}[x;]')til count x:flip x}\"\"\") # / table to matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f19093",
   "metadata": {},
   "source": [
    "* **prepareData**: Create the train and test datasets. Select the model needed columns *columns* from the table grouped by traffic station. For each traffic station it lefts *ntest* rows for test. It divide the data with chunks of length *chunkLen*. Finally it create a list of dictionaries for training data and training target (the load column) and test data target.\n",
    "    \n",
    "    First off, regardless of whether we needed the train or test output, we needed to get either the last *ntest* records or up to the last *ntest* records. Since we needed to repeat this operation for the given columns, we decided that a functional statement would be the best fit.\n",
    "\n",
    "    Once we shaped the data the way we needed, it was time to build the list of matrices. This needed to be done using a sliding window but, in order to return a list of matrices (not a list of tables), we used the **toMatrix** function to transform a table to a matrix and **sw** (sliding window) function to apply the sliding window based on a single huge matrix.\n",
    "\n",
    "    As for the y data, we used the function **gt** (get target) that returned the target (traffic load) as a list with the first *chunkLen*+1 entries removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee2d829",
   "metadata": {},
   "outputs": [],
   "source": [
    "_=kx.q(\"\"\"\n",
    "        prepareData:{[data; ntest; chunkLen; columns; locTarget]  \n",
    "            train:(toMatrix')?[data;();`traffic_station;columns!({(y;(-;(count;x);z);x)}[;_;ntest]')columns]; \n",
    "            test:(toMatrix')?[data;();`traffic_station;columns!({(y;(-;(count;x);z);x)}[;#;ntest]')columns];                                                                               \n",
    "            (((sw[;chunkLen]')test;(gt[;chunkLen;locTarget]')test);((sw[;chunkLen]')train;(gt[;chunkLen;locTarget]')train))   \n",
    "        }\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff89f11c",
   "metadata": {},
   "source": [
    "Lets test this function with only one station:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3582d795-fd07-41c4-bbba-4c6d20c459d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c724aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_id = 4010\n",
    "\n",
    "station = kx.q.qsql.select(final, where=[\"traffic_station=\"+str(station_id)])\n",
    "\n",
    "data = kx.q(\"prepareData\", station, 500, 5, kx.SymbolVector(['rainfall', 'traffic_load', 'hour', 'weekday']), 1)\n",
    "\n",
    "X_train, y_train = np.array(data[0][0][station_id].py()), np.array(data[0][1][station_id].py())\n",
    "X_test, y_test =  np.array(data[1][0][station_id].py()), np.array(data[1][1][station_id].py())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9325cfc2",
   "metadata": {},
   "source": [
    "And now we will try this datasets with a simple LSTM model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373dcc07-c7db-4312-b6ef-161eca4a16c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdee7af9-ed41-4e07-9083-5b70be5c433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7b6281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(units = 50, return_sequences=False, input_shape=[None,4]))\n",
    "model.add(Dense(units = 1))\n",
    "\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    epochs=50, batch_size=8, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    verbose=0, shuffle=False)\n",
    "\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1619cf69",
   "metadata": {},
   "source": [
    "We can see the performance of the model in the following graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a9930f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_test, label='test real')\n",
    "plt.plot(range(400,495), model.predict(X_test[400:], verbose=0).flatten(), label='test predict')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f44baa6-a169-453b-8ebf-2d4424e4299f",
   "metadata": {},
   "source": [
    "(TBD: performance gains? which are the key aspects to be migrated into q? pandas queries ... anything else? What I'd like is something like: it's clear what we have to do: read and clean tables, etc. This is done in python using pandas, using ... whatever. What we are going to do is to do this part using qsql, this other using ... You have to think of the following situation: with all you know now, you are requested to tell someone how to migrate some pythonic code into pykx, what would you tell her to start from? which things are the most important one to migrate? etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779e8dfc-b6bc-43d2-9520-f659c808c3a4",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b> üîç You can find on Github the resulting <a href=\"https://github.com/hablapps/AllRoadsLeadToPyKX/blob/Python-Version-Pre/AllRoadsLeadToPyKX.md\">PyKX-enhanced Pythonic version</a>. </b> (TBD: fix url)\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ef6b1f",
   "metadata": {},
   "source": [
    "## pykx.q migration <a class=\"anchor\" id=\"t4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256c9934",
   "metadata": {},
   "source": [
    "When the team got comfortable with the q language they started using it almost entirely through `kx.q()`, as it was more concise. But the programming became somewhat tedious having to use strings. This is why it was decided to jump to a q environment. But as seen in the previous chapter, there was Python code that the team couldn't port to q. For this reason it was decided to stay in PyKX but this time in the q environment.\n",
    "\n",
    "**pykx.q** allows Python code execution on a q environment and, as a result, it opens up the door for new opportunities when dealing with existing codebases as it allows for importing and using Python libraries, both installed on the system and available as .py files.\n",
    "\n",
    "In our case we use both of these options. We will focus on these opportunities to use Python code in pykx.q and leave the link to the project's [q script]() for the interested reader.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <b> üîç You can find on Github the resulting <a href=\"https://github.com/hablapps/AllRoadsLeadToPyKX/blob/Python-Version-Pre/AllRoadsLeadToPyKX.md\">PyKX-enhanced kdb+/q version</a>. (TBD: fix url)</b>\n",
    "</div>\n",
    "\n",
    "First, we want to execute the `haversine_vector` function to measure the distance between coordinates. Since it's not available on q, we decided to use pykx.q to incorporate this library straight into our q code with these lines:\n",
    "\n",
    "```q\n",
    ".pykx.pyexec\"from haversine import haversine_vector, Unit\";\n",
    "```\n",
    "\n",
    "This function expects two Pandas DataFrames as input, so we need to change the default conversion type from \"np\" or Numpy to \"pd\" or Pandas:\n",
    "\n",
    "```q\n",
    ".pykx.setdefault\"pd\";\n",
    "```\n",
    "\n",
    "Having done this, we can \"move\" our input variables to the Python memory space using `.pykx.set`\n",
    "\n",
    "```q\n",
    ".pykx.set[`a;`longitude`latitude#a];\n",
    ".pykx.set[`b;`longitude`latitude#b];\n",
    "```\n",
    "\n",
    "And finally execute our function\n",
    "\n",
    "```q\n",
    "(.pykx.eval\"haversine_vector(a, b, Unit.KILOMETERS, comb=True)\")`\n",
    "```\n",
    "\n",
    "Notice the backtick at the end, this is for converting back to a q type.\n",
    "\n",
    "\n",
    "\n",
    "The other way we can run Python code is to load a .py (renamed to .p) file using `\\l`. This could be done as follows:\n",
    "\n",
    "```q\n",
    "system\"l kerasmodel.p\";\n",
    "```\n",
    "\n",
    "Here we have defined two functions named `fit` and `predict`. We can load them and use them like this:\n",
    "\n",
    "```q\n",
    "modelfit:.pykx.get`fit;\n",
    "modelfit[train[0][3403];train[1][3403];test[0][3403];test[1][3403]];\n",
    "modelpredict:.pykx.get`predict;\n",
    "res:modelpredict[train[0][3403]];\n",
    "```\n",
    "\n",
    "(TBD) Some performance results from this version?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8d2b41",
   "metadata": {},
   "source": [
    "## Final thoughts <a class=\"anchor\" id=\"t5\"></a>\n",
    "\n",
    "Ultimately, the project was a resounding success. We succeeded in transforming a codebase plagued by disorganization and performance concerns into a streamlined and competitive solution, empowered by Kdb+/q. PyKX is designed in a way that allows more experienced profiles and new kdb+/q developers to coexist in the same development environment. This favors the collaboration among a diversely experienced team. This is thanks to the different levels of integration that PyKX has and their compatibility with each other as it serves as an accessible introduction to Kdb+/q for less-experienced team members, further enhancing our team's capabilities.\n",
    "\n",
    "The pykx.q library allows, as we have discussed earlier, to use existing Python codebases. This feature is really useful, specially when dealing with code migrations from Python. Through our experience, we identified challenges in aligning Python input shapes with their counterparts converted from q. After using the `.pykx.set` function for conversion to Python, we often needed to manipulate these transformed objects within the Python environment or modify the default conversion type to match the expected input format of Python functions.. Once that was dealt with, the experience using this library was really nice and technically impressive.\n",
    "\n",
    "Since the data we needed to transfer back and forth between memory spaces was not that big (we were cautious this was the case) we observed no perceptible loss in performance. Instead, we achieved a significant improvement compared to Pandas.\n",
    "\n",
    "Overall we would rate both PyKX libraries highly since it enables users to reuse existing code, significantly reducing the time required for migrations between these two languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f1c17a",
   "metadata": {},
   "source": [
    "## Bibliography <a class=\"anchor\" id=\"t5\"></a>\n",
    "\n",
    "* Vidas M, Tubiƒá V, Ivanoviƒá I, Subotiƒá M. Sustainability (Basel) 2022; 14(9): e4985, http://dx.doi.org/10.3390/su14094985  \n",
    "* Y. Yao et al., \"Analyzing the Effects of Rainfall on Urban Traffic-Congestion Bottlenecks,\" in IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, vol. 13, pp. 504-512, 2020, http://dx.doi.org/10.1109/JSTARS.2020.2966591  \n",
    "* Essien, A., Petrounias, I., Sampaio, P., & Sampaio, S. (2018). The Impact of Rainfall and Temperature on Peak\n",
    "and Off-Peak Urban Traffic. In Database and Expert Systems Applications : 28th International Conference, DEXA\n",
    "2018, Regensburg, Germany. (pp. 399-407). (Lecture Notes in Computer Science). Springer Nature.\n",
    "https://doi.org/10.1007/978-3-319-98812-2_36  \n",
    "(TBD: new refs - need formatting .. )\n",
    "* A. Morrison and N. Crone, Accelerating Python Workflows using PyKX, June 2023, KX Developers blog, https://kx.com/blog/accelerating-python-workflows-using-pykx/\n",
    "* Reuben Taylor. An Introduction to PyKXhttps://kx.com/videos/an-introduction-to-pykx/ June, 2023\n",
    "* Paul Walsh PyKX Boosts Trade Analytics https://www.treliant.com/knowledge-center/pykx-boosts-trade-analytics/ June 26, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8b8049-77ae-4d88-a9bc-6c4da2b59dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
